import streamlit as st
import pandas as pd
import datetime
import urllib.request
import json
import re

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Royal Canin Deep Monitor",
    page_icon="ğŸ“¡",
    layout="wide"
)

# 2. HTML íƒœê·¸ ì œê±° í•¨ìˆ˜
def clean_html(raw_html):
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return cleantext.replace("&quot;", "'").replace("&lt;", "<").replace("&gt;", ">").replace("&amp;", "&")

# 3. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (1000ê°œê¹Œì§€ ê¹Šê²Œ íƒìƒ‰ + ë²„ë¦¬ëŠ” ë°ì´í„° ì—†ìŒ)
def get_data_deep_scan(keyword_string, exclude_string, client_id, client_secret):
    if not client_id or not client_secret:
        return None, []
    
    keywords = [k.strip() for k in keyword_string.split(',') if k.strip()]
    excludes = [e.strip() for e in exclude_string.split(',') if e.strip()]
    
    category = "cafearticle"
    all_data = []
    log_messages = []
    
    status_area = st.empty()
    progress_bar = st.progress(0)
    
    # 30ì¼ ìœ í†µê¸°í•œ
    now = datetime.datetime.now()
    cutoff_date = now - datetime.timedelta(days=30)
    
    # [ì„¤ì •] ìµœëŒ€ íƒìƒ‰ í˜ì´ì§€ ìˆ˜ (10í˜ì´ì§€ = 1000ê°œ)
    # ëˆ„ë½ì„ ë§‰ê¸° ìœ„í•´ ë²”ìœ„ë¥¼ ëŒ€í­ ëŠ˜ë ¸ìŠµë‹ˆë‹¤.
    MAX_PAGES = 10 
    
    total_keywords = len(keywords)
    
    for k_idx, search_term in enumerate(keywords):
        for page in range(1, MAX_PAGES + 1):
            # ì§„í–‰ë¥  í‘œì‹œ
            start_index = (page - 1) * 100 + 1
            progress = (k_idx * MAX_PAGES + page) / (total_keywords * MAX_PAGES)
            progress_bar.progress(min(progress, 1.0))
            
            try:
                status_area.info(f"ğŸ“¡ '{search_term}' {start_index}~{start_index+99}ë²ˆì§¸ ê¸€ ìŠ¤ìº” ì¤‘...")
                
                query_str = search_term
                if excludes:
                    for exc in excludes:
                        query_str += f" -{exc}"
                
                encText = urllib.parse.quote(query_str)
                # sort=date (ìµœì‹ ìˆœ ìš”ì²­)
                url = f"https://openapi.naver.com/v1/search/{category}?query={encText}&display=100&start={start_index}&sort=date"
                
                request = urllib.request.Request(url)
                request.add_header("X-Naver-Client-Id", client_id)
                request.add_header("X-Naver-Client-Secret", client_secret)
                
                response = urllib.request.urlopen(request)
                
                if response.getcode() == 200:
                    data = json.loads(response.read().decode('utf-8'))
                    items = data['items']
                    
                    if not items: break # ë” ì´ìƒ ê¸€ì´ ì—†ìœ¼ë©´ ë‹¤ìŒ í‚¤ì›Œë“œë¡œ

                    for item in items:
                        # ë‚ ì§œ ë³€í™˜
                        raw_date = item.get('postdate', '')
                        try:
                            if raw_date:
                                p_date = pd.to_datetime(raw_date, format='%Y%m%d')
                            else:
                                p_date = pd.to_datetime('1900-01-01')
                        except:
                            p_date = pd.to_datetime('1900-01-01')
                        
                        # 30ì¼ ì§€ë‚œ ê¸€ ì œì™¸
                        if p_date.year > 2000 and p_date < cutoff_date:
                            continue 
                        
                        # ì»¤ë®¤ë‹ˆí‹° ë¶„ë¥˜ (4ëŒ€ì¥ + ê¸°íƒ€)
                        raw_name = item.get('cafename', '')
                        is_target = False
                        
                        if "ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼" in raw_name or "ê³ ë‹¤" in raw_name: 
                            source_label = "ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼"
                            is_target = True
                        elif "ê°•ì‚¬ëª¨" in raw_name: 
                            source_label = "ê°•ì‚¬ëª¨"
                            is_target = True
                        elif "ì•„ë°˜ê°•ê³ " in raw_name: 
                            source_label = "ì•„ë°˜ê°•ê³ "
                            is_target = True
                        elif "ëƒ¥ì´ë„¤" in raw_name: 
                            source_label = "ëƒ¥ì´ë„¤"
                            is_target = True
                        else: 
                            # ëˆ„ë½ í™•ì¸ì„ ìœ„í•´ 'ê¸°íƒ€'ë„ ì¼ë‹¨ ìˆ˜ì§‘ì€ í•¨ (í™”ë©´ì—ì„œ ë¶„ë¦¬)
                            source_label = f"ê¸°íƒ€ ({raw_name})"
                            is_target = False

                        item['source'] = source_label
                        item['is_target'] = is_target # 4ëŒ€ ì»¤ë®¤ë‹ˆí‹° ì—¬ë¶€ íƒœê·¸
                        item['clean_title'] = clean_html(item['title'])
                        item['clean_desc'] = clean_html(item['description'])
                        item['postdate_dt'] = p_date
                        item['search_keyword'] = "ë¡œì–„ìºë‹Œ"
                        
                        all_data.append(item)
                else:
                    break
            except Exception as e:
                log_messages.append(f"âŒ ì—ëŸ¬: {e}")
                break
    
    status_area.success(f"âœ… ìŠ¤ìº” ì™„ë£Œ! ì´ {len(all_data)}ê°œ ê¸€ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
    progress_bar.empty()
    
    if not all_data:
        return pd.DataFrame(), log_messages

    df = pd.DataFrame(all_data)
    
    # ìœ„í—˜ í‚¤ì›Œë“œ
    risk_keywords = ['ë²Œë ˆ', 'ì´ë¬¼', 'êµ¬ë”ê¸°', 'íšŒìˆ˜', 'ì‹ì•½ì²˜', 'ì‹ ê³ ', 'í™˜ë¶ˆ', 'í† í•´', 'ì„¤ì‚¬', 'í˜ˆë³€', 'ê³°íŒ¡ì´', 'ì¶©ê²©', 'ì‹¤ë§', 'ë°°ì‹ ', 'ë¦¬ì½œ']
    
    def check_risk(text):
        for k in risk_keywords:
            if k in text:
                return f"ğŸš¨ ë°œê²¬: {k}"
        return "ì¼ë°˜"

    df['risk_level'] = df['clean_desc'].apply(check_risk)
    
    # [ì •ë ¬] ë‚ ì§œìˆœ (1900ë…„ì€ ìµœì‹ ìœ¼ë¡œ)
    df['sort_helper'] = df['postdate_dt'].apply(lambda x: now if x.year == 1900 else x)
    df = df.sort_values(by='sort_helper', ascending=False)
    
    # [ì¤‘ë³µ ì œê±°]
    df = df.drop_duplicates(['clean_title'], keep='first')
    
    return df[['postdate_dt', 'source', 'is_target', 'clean_title', 'clean_desc', 'risk_level', 'link', 'search_keyword', 'sort_helper']], log_messages

# 4. UI êµ¬ì„±
with st.sidebar:
    st.header("ğŸ“¡ ë”¥ ìŠ¤ìº” ëª¨ë‹ˆí„°ë§")
    st.caption("ëˆ„ë½ ë°©ì§€ë¥¼ ìœ„í•´ ë” ê¹Šê²Œ(10í˜ì´ì§€) ê²€ìƒ‰í•©ë‹ˆë‹¤.")
    
    default_keywords = "ë¡œì–„ìºë‹Œ, ë¡œìº, ë¡œì¼€"
    keyword_input = st.text_input("ê²€ìƒ‰ì–´", value=default_keywords)
    
    exclude_input = st.text_input("ì œì™¸ì–´", value="ã„¹ã…‡ã…‹ã„´, ê´‘ê³ , ë¶„ì–‘, íŒë‹ˆë‹¤")
    
    st.markdown("---")
    client_id = st.text_input("Client ID", type="password")
    client_secret = st.text_input("Secret", type="password")
    run_btn = st.button("ì •ë°€ ë¶„ì„ ì‹œì‘")

st.title(f"ğŸ“¡ '{keyword_input}' ì •ë°€ íƒ€ì„ë¼ì¸")

# í”¼ë“œ ë Œë”ë§ í•¨ìˆ˜ (ë¬´ì¡°ê±´ ì¬ì •ë ¬)
def render_feed(dataframe):
    if dataframe.empty:
        st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í™”ë©´ì— ê·¸ë¦¬ê¸° ì§ì „ì— ë‹¤ì‹œ í•œë²ˆ ì •ë ¬ (íƒ­ ê°„ ì´ë™ ì‹œ ê¼¬ì„ ë°©ì§€)
    sorted_df = dataframe.sort_values(by='sort_helper', ascending=False)

    for i, row in sorted_df.iterrows():
        with st.container():
            if row['postdate_dt'].year == 1900:
                date_str = "âš¡ ìµœì‹  (ë‚ ì§œë¯¸ìƒ)"
                date_color = "red"
            else:
                date_str = row['postdate_dt'].strftime('%Y-%m-%d')
                date_color = "gray"
            
            if "ğŸš¨" in row['risk_level']:
                title_prefix = "ğŸš¨ "
            else:
                title_prefix = ""

            st.markdown(f"**[{row['source']}]** <span style='color:{date_color}'>{date_str}</span>", unsafe_allow_html=True)
            st.markdown(f"##### {title_prefix}{row['clean_title']}")
            
            if "ğŸš¨" in row['risk_level']:
                    st.write(f"âš ï¸ **{row['risk_level']}**")
            
            st.caption(row['clean_desc'])
            st.markdown(f"[ì›ë¬¸ ë³´ëŸ¬ê°€ê¸°]({row['link']})")
            st.divider()

if run_btn:
    if not client_id or not client_secret:
        st.error("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        df, logs = get_data_deep_scan(keyword_input, exclude_input, client_id, client_secret)
        
        with st.expander("â„¹ï¸ ë¡œê·¸ í™•ì¸"):
            if logs:
                for log in logs: st.write(log)

        if df is not None and not df.empty:
            
            # 4ëŒ€ ì»¤ë®¤ë‹ˆí‹° ë°ì´í„°ë§Œ í•„í„°ë§
            target_df = df[df['is_target'] == True]
            # ê¸°íƒ€ ë°ì´í„° (ëˆ„ë½ í™•ì¸ìš©)
            other_df = df[df['is_target'] == False]
            
            col1, col2, col3 = st.columns(3)
            risk_count = len(target_df[target_df['risk_level'] != "ì¼ë°˜"])
            
            if not target_df.empty:
                latest_date = target_df.iloc[0]['postdate_dt']
                latest_str = "âš¡ ë°©ê¸ˆ" if latest_date.year == 1900 else latest_date.strftime('%Y-%m-%d')
            else:
                latest_str = "-"
                
            col1.metric("4ëŒ€ ì»¤ë®¤ë‹ˆí‹° ê¸€", f"{len(target_df)}ê±´")
            col2.metric("ğŸš¨ ì´ìŠˆ ë°œê²¬", f"{risk_count}ê±´", delta_color="inverse")
            col3.metric("ê°€ì¥ ìµœì‹  ê¸€", latest_str)
            
            st.markdown("---")
            
            # íƒ­ êµ¬ì„± (ê¸°íƒ€ íƒ­ ì¶”ê°€ë¨!)
            tabs = st.tabs([
                "ğŸ”¥ ì „ì²´ (4ëŒ€ì¥)", 
                "ğŸ˜º ê³ ë‹¤", 
                "ğŸ˜º ëƒ¥ì´ë„¤", 
                "ğŸ¶ ê°•ì‚¬ëª¨", 
                "ğŸ¶ ì•„ë°˜ê°•ê³ ",
                "ğŸ—‘ï¸ ê¸°íƒ€/ì œì™¸ëœ ê¸€ (ëˆ„ë½í™•ì¸)" 
            ])
            
            # 1. ì „ì²´ (4ëŒ€ ì»¤ë®¤ë‹ˆí‹°ë§Œ)
            with tabs[0]:
                render_feed(target_df)
            
            # 2. ê³ ë‹¤
            with tabs[1]:
                render_feed(target_df[target_df['source'] == "ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼"])
            
            # 3. ëƒ¥ì´ë„¤
            with tabs[2]:
                render_feed(target_df[target_df['source'] == "ëƒ¥ì´ë„¤"])
            
            # 4. ê°•ì‚¬ëª¨
            with tabs[3]:
                render_feed(target_df[target_df['source'] == "ê°•ì‚¬ëª¨"])

            # 5. ì•„ë°˜ê°•ê³ 
            with tabs[4]:
                render_feed(target_df[target_df['source'] == "ì•„ë°˜ê°•ê³ "])
            
            # 6. ê¸°íƒ€ (ëˆ„ë½ëœ ê²Œ ì—¬ê¸° ìˆë‚˜ í™•ì¸ìš©)
            with tabs[5]:
                st.warning("ğŸ‘‡ ì—¬ê¸°ëŠ” 4ëŒ€ ì»¤ë®¤ë‹ˆí‹°ê°€ ì•„ë‹ˆë¼ì„œ ë©”ì¸ í™”ë©´ì—ì„œ ì œì™¸ëœ ê¸€ë“¤ì…ë‹ˆë‹¤.")
                st.info("ë§Œì•½ 'ê³ ë‹¤' ê¸€ì¸ë° ì—¬ê¸°ì— ì™€ìˆë‹¤ë©´, ì¹´í˜ ì´ë¦„ ì¸ì‹ì´ ì˜ëª»ëœ ê²ƒì…ë‹ˆë‹¤.")
                render_feed(other_df)

        else:
            st.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
