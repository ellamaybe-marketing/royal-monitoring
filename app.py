import streamlit as st
import pandas as pd
import datetime
import urllib.request
import json
import re

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Total Monitor (Blog + Cafe)",
    page_icon="ğŸ”",
    layout="wide"
)

# 2. HTML íƒœê·¸ ì œê±° í•¨ìˆ˜
def clean_html(raw_html):
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return cleantext.replace("&quot;", "'").replace("&lt;", "<").replace("&gt;", ">").replace("&amp;", "&")

# 3. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ê¸´ ì´ë¦„ ë§¤í•‘ ë¡œì§ ê°•í™”)
def get_naver_data_integrated(keyword, client_id, client_secret):
    if not client_id or not client_secret:
        return None, 0, 0
    
    categories = ["blog", "cafearticle"]
    all_data = []
    
    # ìµœê·¼ 30ì¼ ë°ì´í„° ì¡°íšŒ (ì¹´í˜ ê¸€ í™•ë³´ë¥¼ ìœ„í•´ ë„‰ë„‰í•˜ê²Œ)
    today = datetime.datetime.now()
    cutoff_date = today - datetime.timedelta(days=30)
    
    count_blog = 0
    count_cafe = 0
    
    status_text = st.empty() 
    
    for cat in categories:
        # 5í˜ì´ì§€(500ê°œ)ê¹Œì§€ íƒìƒ‰
        for start_index in range(1, 500, 100):
            try:
                cat_name_kr = "ë¸”ë¡œê·¸" if cat == "blog" else "ì¹´í˜"
                status_text.text(f"ğŸ” {cat_name_kr} ë°ì´í„°ë¥¼ {start_index}ë²ˆë¶€í„° ì°¾ëŠ” ì¤‘...")
                
                encText = urllib.parse.quote(keyword)
                url = f"https://openapi.naver.com/v1/search/{cat}?query={encText}&display=100&start={start_index}&sort=date"
                
                request = urllib.request.Request(url)
                request.add_header("X-Naver-Client-Id", client_id)
                request.add_header("X-Naver-Client-Secret", client_secret)
                
                response = urllib.request.urlopen(request)
                
                if response.getcode() == 200:
                    data = json.loads(response.read().decode('utf-8'))
                    items = data['items']
                    
                    if not items: break

                    for item in items:
                        # ë‚ ì§œ ì²´í¬
                        try:
                            p_date = pd.to_datetime(item['postdate'], format='%Y%m%d')
                        except:
                            continue
                        
                        if p_date < cutoff_date:
                            continue 
                        
                        # ---------------------------------------------------------
                        # [í•µì‹¬] ê¸´ ì¹´í˜ ì´ë¦„ì„ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ëŠ” ë¶€ë¶„
                        # ---------------------------------------------------------
                        raw_name = item.get('cafename', '') # APIê°€ ì£¼ëŠ” ì›ë³¸ ì´ë¦„ (ì—„ì²­ ê¹€)
                        
                        if cat == "blog":
                            source_label = "ë„¤ì´ë²„ ë¸”ë¡œê·¸"
                            count_blog += 1
                        else:
                            count_cafe += 1
                            # API ì›ë³¸ ì´ë¦„ì— íŠ¹ì • ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì§§ì€ ì´ë¦„ìœ¼ë¡œ ë³€ê²½
                            
                            # 1. ê°•ì‚¬ëª¨ (ì›ë³¸: ê°•ì‚¬ëª¨-ë°˜ë ¤ê²¬ í›ˆë ¨ êµìœ¡ë²•, ê°•ì•„ì§€ ì¢…ë¥˜...)
                            if "ê°•ì‚¬ëª¨" in raw_name: 
                                source_label = "ê°•ì‚¬ëª¨"
                            
                            # 2. ëƒ¥ì´ë„¤ (ì›ë³¸: ëƒ¥ì´ë„¤-ê³ ì–‘ì´ë¥¼ ì‚¬ë‘í•˜ëŠ” ëª¨ì„,ê¸¸ ê³ ...)
                            elif "ëƒ¥ì´ë„¤" in raw_name: 
                                source_label = "ëƒ¥ì´ë„¤"
                            
                            # 3. ì•„ë°˜ê°•ê³  (ì›ë³¸: ì•„ë°˜ê°•ê³  íë§ì¹´í˜ ì•„í”ˆ ë°˜ë ¤ ê°•ì•„ì§€ì™€...)
                            elif "ì•„ë°˜ê°•ê³ " in raw_name: 
                                source_label = "ì•„ë°˜ê°•ê³ "
                            
                            # 4. ê³ ë‹¤ (ì›ë³¸: ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼)
                            elif "ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼" in raw_name: 
                                source_label = "ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼"
                                
                            else: 
                                # 4ëŒ€ ì¹´í˜ê°€ ì•„ë‹ˆë©´ 'ê¸°íƒ€'ë¡œ í‘œì‹œí•˜ë˜, ê´„í˜¸ ì•ˆì— ì›ë³¸ ì´ë¦„ í‘œì‹œ
                                source_label = f"ê¸°íƒ€ ì¹´í˜ ({raw_name})"
                        
                        item['source'] = source_label
                        item['clean_title'] = clean_html(item['title'])
                        item['clean_desc'] = clean_html(item['description'])
                        item['postdate_dt'] = p_date
                        all_data.append(item)
                else:
                    break
            except Exception as e:
                print(f"Error: {e}")
                break
                
    status_text.empty()
    
    if not all_data:
        return pd.DataFrame(), count_blog, count_cafe

    df = pd.DataFrame(all_data)
    
    # ìœ„í—˜ í‚¤ì›Œë“œ
    risk_keywords = ['êµ¬ë”ê¸°', 'ë²Œë ˆ', 'ì´ë¬¼ì§ˆ', 'ì‹ì•½ì²˜', 'ì‹ ê³ ', 'í™˜ë¶ˆ', 'í† í•´', 'ì„¤ì‚¬', 'í˜ˆë³€', 'ê³°íŒ¡ì´', 'ë¦¬ì½œ', 'ë°°ì‹ ', 'ì‹¤ë§']
    df['risk_level'] = df['clean_desc'].apply(lambda x: "ğŸš¨ ì‹¬ê°/ì£¼ì˜" if any(k in x for k in risk_keywords) else "ì¼ë°˜")
    
    df = df.drop_duplicates(['clean_title'])
    df = df.sort_values(by='postdate_dt', ascending=False)
    
    return df[['postdate_dt', 'source', 'clean_title', 'clean_desc', 'risk_level', 'link']], count_blog, count_cafe

# 4. ë©”ì¸ í™”ë©´ UI
with st.sidebar:
    st.header("âš™ï¸ í†µí•© ëª¨ë‹ˆí„°ë§")
    keyword = st.text_input("ê²€ìƒ‰ì–´", value="ë¡œì–„ìºë‹Œ")
    
    st.markdown("---")
    st.caption("ë³´ê³  ì‹¶ì€ ì±„ë„ í•„í„°")
    
    # í•„í„° ì˜µì…˜ë„ ê¹”ë”í•œ ì´ë¦„ìœ¼ë¡œ í†µì¼
    all_options = ["ë„¤ì´ë²„ ë¸”ë¡œê·¸", "ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼", "ëƒ¥ì´ë„¤", "ì•„ë°˜ê°•ê³ ", "ê°•ì‚¬ëª¨"]
    target_filter = st.multiselect(
        "ì±„ë„ ì„ íƒ (ê¸°íƒ€ ì¹´í˜ëŠ” ìë™ ì œì™¸ë¨)",
        all_options,
        default=all_options 
    )
    
    st.markdown("---")
    st.info("API í‚¤ ì…ë ¥")
    client_id = st.text_input("Client ID", type="password")
    client_secret = st.text_input("Secret", type="password")
    
    run_btn = st.button("ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")

st.title(f"ğŸ‘€ '{keyword}' ì—¬ë¡  ë¶„ì„ (ìµœê·¼ 30ì¼)")

if run_btn:
    if not client_id or not client_secret:
        st.error("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ë¸”ë¡œê·¸ì™€ ì¹´í˜ë¥¼ ì •ë°€ ë¶„ì„ ì¤‘..."):
            df, c_blog, c_cafe = get_naver_data_integrated(keyword, client_id, client_secret)

        # ì§„ë‹¨ ë©”ì‹œì§€
        if c_cafe == 0 and c_blog > 0:
             st.warning(f"âš ï¸ ë¸”ë¡œê·¸ ê¸€({c_blog}ê°œ)ì€ ì°¾ì•˜ìœ¼ë‚˜, ì¹´í˜ ê¸€ì€ 0ê°œì…ë‹ˆë‹¤. (ê²€ìƒ‰ì–´ ê´€ë ¨ ìµœê·¼ 30ì¼ ì¹´í˜ ê¸€ ì—†ìŒ)")
        elif c_cafe == 0 and c_blog == 0:
             st.error("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. API í‚¤ì™€ ê²€ìƒ‰ì–´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
             st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! (ë¸”ë¡œê·¸: {c_blog}ê±´ / ì¹´í˜: {c_cafe}ê±´)")

        if df is not None and not df.empty:
            # í•„í„°ë§ ì ìš© (ì‚¬ìš©ìê°€ ì„ íƒí•œ ê¹”ë”í•œ ì´ë¦„ ê¸°ì¤€)
            if target_filter:
                filtered_df = df[df['source'].isin(target_filter)]
            else:
                filtered_df = df
            
            if filtered_df.empty:
                st.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ëŠ” ìˆìœ¼ë‚˜, í•„í„° ì„¤ì • ë•Œë¬¸ì— í™”ë©´ì— ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. í•„í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                # ìš”ì•½ ì§€í‘œ
                col1, col2, col3 = st.columns(3)
                risk_count = len(filtered_df[filtered_df['risk_level'] == "ğŸš¨ ì‹¬ê°/ì£¼ì˜"])
                
                # ìµœë¹ˆê°’ ì—ëŸ¬ ë°©ì§€
                if not filtered_df.empty:
                    top_source = filtered_df['source'].mode()[0]
                else:
                    top_source = "-"
                
                col1.metric("í‘œì‹œëœ ê²Œì‹œê¸€", f"{len(filtered_df)}ê±´")
                col2.metric("ìœ„í—˜(ì´ìŠˆ) ê¸€", f"{risk_count}ê±´", delta_color="inverse")
                col3.metric("ìµœë‹¤ ì–¸ê¸‰", top_source)
                
                st.markdown("---")

                # íƒ­ êµ¬ì„±
                tab1, tab2, tab3 = st.tabs(["ğŸ”¥ ìœ„í—˜ê¸€(Risk)", "ğŸ“Š ì±„ë„ë³„ ë¹„ì¤‘", "ğŸ“ ì „ì²´ ë¦¬ìŠ¤íŠ¸"])
                
                with tab1:
                    risk_df = filtered_df[filtered_df['risk_level'] == "ğŸš¨ ì‹¬ê°/ì£¼ì˜"]
                    if risk_df.empty:
                        st.success("âœ… ê°ì§€ëœ ìœ„í—˜ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        for i, row in risk_df.iterrows():
                            with st.container():
                                icon = "ğŸ…±ï¸" if "ë¸”ë¡œê·¸" in row['source'] else "â˜•"
                                st.error(f"**{icon} [{row['source']}] {row['postdate_dt'].date()}** | {row['clean_title']}")
                                st.write(row['clean_desc'])
                                st.markdown(f"[ì›ë¬¸ ë³´ëŸ¬ê°€ê¸°]({row['link']})")
                                st.divider()

                with tab2:
                    st.bar_chart(filtered_df['source'].value_counts())

                with tab3:
                    display_df = filtered_df.copy()
                    display_df['ë‚ ì§œ'] = display_df['postdate_dt'].dt.date
                    # ë§í¬ ì»¬ëŸ¼ ì„¤ì •
                    st.dataframe(
                        display_df[['ë‚ ì§œ', 'source', 'clean_title', 'risk_level', 'link']],
                        column_config={"link": st.column_config.LinkColumn("ë§í¬")},
                        use_container_width=True
                    )
