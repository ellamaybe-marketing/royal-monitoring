import streamlit as st
import pandas as pd
import datetime
import urllib.request
import json
import re

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Royal Canin Final Monitor",
    page_icon="ğŸ“…",
    layout="wide"
)

# 2. HTML íƒœê·¸ ì œê±° í•¨ìˆ˜
def clean_html(raw_html):
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return cleantext.replace("&quot;", "'").replace("&lt;", "<").replace("&gt;", ">").replace("&amp;", "&")

# 3. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ë‚ ì§œ ì •í™•ë„ ê°œì„ )
def get_naver_data_final(keyword, client_id, client_secret):
    if not client_id or not client_secret:
        return None, []
    
    categories = ["blog", "cafearticle"]
    all_data = []
    log_messages = []
    
    status_area = st.empty()
    
    for cat in categories:
        cat_name = "ë¸”ë¡œê·¸" if cat == "blog" else "ì¹´í˜"
        
        # 5í˜ì´ì§€(500ê°œ) íƒìƒ‰
        for start_index in range(1, 500, 100):
            try:
                status_area.info(f"ğŸƒâ€â™‚ï¸ {cat_name} {start_index}ë²ˆì§¸ ê¸€ ë¶„ì„ ì¤‘...")
                
                encText = urllib.parse.quote(keyword)
                # ë‚ ì§œìˆœ ì •ë ¬ (sort=date)
                url = f"https://openapi.naver.com/v1/search/{cat}?query={encText}&display=100&start={start_index}&sort=date"
                
                request = urllib.request.Request(url)
                request.add_header("X-Naver-Client-Id", client_id)
                request.add_header("X-Naver-Client-Secret", client_secret)
                
                response = urllib.request.urlopen(request)
                
                if response.getcode() == 200:
                    data = json.loads(response.read().decode('utf-8'))
                    items = data['items']
                    
                    if not items:
                        break

                    for item in items:
                        # [í•µì‹¬ ìˆ˜ì •] ë‚ ì§œ ë•œë¹µ ë¡œì§ ì‚­ì œ -> ì›ë³¸ ë‚ ì§œ ìš°ì„  ì‚¬ìš©
                        raw_date = item.get('postdate', '') # YYYYMMDD ë¬¸ìì—´
                        
                        try:
                            if raw_date:
                                p_date = pd.to_datetime(raw_date, format='%Y%m%d')
                            else:
                                # ë‚ ì§œê°€ ì•„ì˜ˆ ì—†ìœ¼ë©´ ë§¨ ë’¤ë¡œ ë³´ë‚´ê¸° ìœ„í•´ ì•„ì£¼ ì˜›ë‚  ë‚ ì§œ ë¶€ì—¬ (ì ˆëŒ€ ì˜¤ëŠ˜ ë‚ ì§œ X)
                                p_date = pd.to_datetime('1900-01-01')
                        except:
                            # ë³€í™˜ ì‹¤íŒ¨ ì‹œì—ë„ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ë®ì–´ì“°ì§€ ì•ŠìŒ
                            p_date = pd.to_datetime('1900-01-01')
                        
                        # ì¹´í˜ ì´ë¦„ ì²˜ë¦¬
                        raw_name = item.get('cafename', '')
                        
                        if cat == "blog":
                            source_label = "ë„¤ì´ë²„ ë¸”ë¡œê·¸"
                        else:
                            # ì´ë¦„ ë§¤ì¹­ (ìš”ì²­í•˜ì‹  ëŒ€ë¡œ)
                            if "ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼" in raw_name or "ê³ ë‹¤" in raw_name: source_label = "ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼"
                            elif "ê°•ì‚¬ëª¨" in raw_name: source_label = "ê°•ì‚¬ëª¨"
                            elif "ì•„ë°˜ê°•ê³ " in raw_name: source_label = "ì•„ë°˜ê°•ê³ "
                            elif "ëƒ¥ì´ë„¤" in raw_name: source_label = "ëƒ¥ì´ë„¤"
                            else: source_label = f"ê¸°íƒ€ ì¹´í˜ ({raw_name})"
                        
                        item['source'] = source_label
                        item['clean_title'] = clean_html(item['title'])
                        item['clean_desc'] = clean_html(item['description'])
                        item['postdate_dt'] = p_date
                        all_data.append(item)
                else:
                    log_messages.append(f"âŒ {cat_name} API í˜¸ì¶œ
