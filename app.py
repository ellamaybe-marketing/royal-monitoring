import streamlit as st
import pandas as pd
import datetime
import urllib.request
import json
import re

# --------------------------------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# --------------------------------------------------------------------------------
st.set_page_config(
    page_title="Community Monitor (ê³ ë‹¤/ëƒ¥ì´ë„¤/ì•„ë°˜ê°•ê³ /ê°•ì‚¬ëª¨)",
    page_icon="ğŸ¾",
    layout="wide"
)

# --------------------------------------------------------------------------------
# 2. ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜
# --------------------------------------------------------------------------------
def clean_html(raw_html):
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return cleantext.replace("&quot;", "'").replace("&lt;", "<").replace("&gt;", ">").replace("&amp;", "&")

def get_naver_data_communities(keyword, client_id, client_secret):
    if not client_id or not client_secret:
        return None
    
    categories = ["cafearticle", "blog"] # ì¹´í˜ ìš°ì„  ê²€ìƒ‰
    all_data = []
    
    today = datetime.datetime.now()
    cutoff_date = today - datetime.timedelta(days=7) # ìµœê·¼ 7ì¼
    
    status_text = st.empty() 
    
    for cat in categories:
        # ìµœëŒ€ 10í˜ì´ì§€(1000ê°œ) íƒìƒ‰
        for start_index in range(1, 1000, 100):
            try:
                status_text.text(f"ğŸ” {cat} ë°ì´í„°ë¥¼ {start_index}ë²ˆë¶€í„° ê¸ì–´ì˜¤ëŠ” ì¤‘...")
                
                encText = urllib.parse.quote(keyword)
                url = f"https://openapi.naver.com/v1/search/{cat}?query={encText}&display=100&start={start_index}&sort=date"
                
                request = urllib.request.Request(url)
                request.add_header("X-Naver-Client-Id", client_id)
                request.add_header("X-Naver-Client-Secret", client_secret)
                
                response = urllib.request.urlopen(request)
                if response.getcode() == 200:
                    data = json.loads(response.read().decode('utf-8'))
                    items = data['items']
                    
                    if not items: break

                    temp_list = []
                    stop_flag = False
                    
                    for item in items:
                        try:
                            p_date = pd.to_datetime(item['postdate'], format='%Y%m%d')
                        except:
                            continue
                            
                        if p_date < cutoff_date:
                            stop_flag = True
                            continue 
                        
                        # --- [í•µì‹¬] ì»¤ë®¤ë‹ˆí‹° ì´ë¦„ ì •ê·œí™” (ë§¤í•‘) ---
                        raw_name = item.get('cafename', '') # ë¸”ë¡œê·¸ëŠ” ì´ ê°’ì´ ì—†ìŒ
                        source_label = "ê¸°íƒ€"
                        
                        if cat == "blog":
                            source_label = "ë¸”ë¡œê·¸"
                        else:
                            # ìš°ë¦¬ê°€ ì°¾ëŠ” 4ëŒ€ ì²œì™•ì¸ì§€ í™•ì¸
                            if "ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼" in raw_name:
                                source_label = "ê³ ë‹¤ (ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼)"
                            elif "ëƒ¥ì´ë„¤" in raw_name:
                                source_
