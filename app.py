import streamlit as st
import pandas as pd
import datetime
import urllib.request
import json
import re

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Royal Canin Multi-Search",
    page_icon="ğŸ•µï¸",
    layout="wide"
)

# 2. HTML íƒœê·¸ ì œê±° í•¨ìˆ˜
def clean_html(raw_html):
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return cleantext.replace("&quot;", "'").replace("&lt;", "<").replace("&gt;", ">").replace("&amp;", "&")

# 3. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ (ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ í•œ ë²ˆì— ê²€ìƒ‰!)
def get_naver_data_multi_keyword(keyword_string, client_id, client_secret):
    if not client_id or not client_secret:
        return None, []
    
    # ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„ëœ ê²€ìƒ‰ì–´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    # ì˜ˆ: "ë¡œì–„ìºë‹Œ, ë¡œìº, ã„¹ã…‡ã…‹ã„´" -> ["ë¡œì–„ìºë‹Œ", "ë¡œìº", "ã„¹ã…‡ã…‹ã„´"]
    keywords = [k.strip() for k in keyword_string.split(',') if k.strip()]
    
    category = "cafearticle"
    all_data = []
    log_messages = []
    
    status_area = st.empty()
    
    # ê° í‚¤ì›Œë“œë³„ë¡œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  í•©ì¹¨
    for search_term in keywords:
        for start_index in range(1, 300, 100): # í‚¤ì›Œë“œë‹¹ 3í˜ì´ì§€ì”©ë§Œ (ì†ë„ ê³ ë ¤)
            try:
                status_area.info(f"ğŸ” í‚¤ì›Œë“œ '{search_term}' ê²€ìƒ‰ ì¤‘... ({start_index}ë²ˆì§¸ ê¸€)")
                
                encText = urllib.parse.quote(search_term)
                # sort=date (ìµœì‹ ìˆœ)
                url = f"https://openapi.naver.com/v1/search/{category}?query={encText}&display=100&start={start_index}&sort=date"
                
                request = urllib.request.Request(url)
                request.add_header("X-Naver-Client-Id", client_id)
                request.add_header("X-Naver-Client-Secret", client_secret)
                
                response = urllib.request.urlopen(request)
                
                if response.getcode() == 200:
                    data = json.loads(response.read().decode('utf-8'))
                    items = data['items']
                    
                    if not items: break

                    for item in items:
                        # ë‚ ì§œ ì²˜ë¦¬
                        raw_date = item.get('postdate', '')
                        try:
                            if raw_date:
                                p_date = pd.to_datetime(raw_date, format='%Y%m%d')
                            else:
                                p_date = pd.to_datetime('1900-01-01')
                        except:
                            p_date = pd.to_datetime('1900-01-01')
                        
                        # ì¹´í˜ ì´ë¦„ ë§¤ì¹­
                        raw_name = item.get('cafename', '')
                        if "ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼" in raw_name or "ê³ ë‹¤" in raw_name: source_label = "ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼"
                        elif "ê°•ì‚¬ëª¨" in raw_name: source_label = "ê°•ì‚¬ëª¨"
                        elif "ì•„ë°˜ê°•ê³ " in raw_name: source_label = "ì•„ë°˜ê°•ê³ "
                        elif "ëƒ¥ì´ë„¤" in raw_name: source_label = "ëƒ¥ì´ë„¤"
                        else: source_label = f"ê¸°íƒ€ ({raw_name})"
                        
                        item['source'] = source_label
                        item['clean_title'] = clean_html(item['title'])
                        item['clean_desc'] = clean_html(item['description'])
                        item['postdate_dt'] = p_date
                        item['search_keyword'] = search_term # ì–´ë–¤ í‚¤ì›Œë“œë¡œ ê±¸ë ¸ëŠ”ì§€ ê¸°ë¡
                        all_data.append(item)
                else:
                    log_messages.append(f"âŒ '{search_term}' í˜¸ì¶œ ì‹¤íŒ¨")
                    break
            except Exception as e:
                log_messages.append(f"âŒ ì—ëŸ¬: {e}")
                break
            
    status_area.success(f"âœ… ì´ {len(keywords)}ê°œ í‚¤ì›Œë“œ ìˆ˜ì§‘ ì™„ë£Œ!")
    
    if not all_data:
        return pd.DataFrame(), log_messages

    df = pd.DataFrame(all_data)
    
    # -----------------------------------------------------------------------
    # [í•µì‹¬] ìœ„í—˜ í‚¤ì›Œë“œ ì •ì˜ (ìš”ì²­í•˜ì‹  ë‹¨ì–´ë“¤ í¬í•¨)
    # -----------------------------------------------------------------------
    risk_keywords = ['ë²Œë ˆ', 'ì´ë¬¼', 'êµ¬ë”ê¸°', 'íšŒìˆ˜', 'ì‹ì•½ì²˜', 'ì‹ ê³ ', 'í™˜ë¶ˆ', 'í† í•´', 'ì„¤ì‚¬', 'í˜ˆë³€', 'ê³°íŒ¡ì´', 'ì¶©ê²©', 'ì‹¤ë§']
    
    def check_risk(text):
        for k in risk_keywords:
            if k in text:
                return f"ğŸš¨ ë°œê²¬ë¨: {k}" # ì–´ë–¤ ë‹¨ì–´ê°€ ê±¸ë ¸ëŠ”ì§€ ì•Œë ¤ì¤Œ
        return "ì¼ë°˜"

    df['risk_level'] = df['clean_desc'].apply(check_risk)
    
    # ì¤‘ë³µ ì œê±° (ì—¬ëŸ¬ í‚¤ì›Œë“œì— ë™ì‹œì— ê±¸ë¦° ê¸€ ì œê±°)
    df = df.drop_duplicates(['clean_title'])
    
    # ë„¤ì´ë²„ ìµœì‹ ìˆœ ìœ ì§€ë¥¼ ìœ„í•´ ì •ë ¬ ë¡œì§ ìƒëµ (ìˆ˜ì§‘ëœ ìˆœì„œê°€ ê³§ ìµœì‹ ìˆœ)
    # ë‹¨, ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ ì„ì—ˆìœ¼ë¯€ë¡œ ë‚ ì§œê°€ ìˆë‹¤ë©´ ë‚ ì§œìˆœ ì •ë ¬ì´ ë” ì•ˆì „í•¨
    # (1900ë…„ ë‚ ì§œì—†ìŒ ë°ì´í„°ëŠ” 'í˜„ì¬'ë¡œ ì·¨ê¸‰í•˜ì—¬ ìƒë‹¨ ë°°ì¹˜)
    now = datetime.datetime.now()
    df['sort_date'] = df['postdate_dt'].apply(lambda x: now if x.year == 1900 else x)
    df = df.sort_values(by='sort_date', ascending=False)
    
    return df[['postdate_dt', 'source', 'clean_title', 'clean_desc', 'risk_level', 'link', 'search_keyword']], log_messages

# 4. UI êµ¬ì„±
with st.sidebar:
    st.header("ğŸ•µï¸ ë‹¤ì¤‘ í‚¤ì›Œë“œ ëª¨ë‹ˆí„°ë§")
    
    # [ìˆ˜ì •] ì—¬ëŸ¬ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥ë°›ë„ë¡ ë³€ê²½
    default_keywords = "ë¡œì–„ìºë‹Œ, ë¡œìº, ë¡œì¼€, ã„¹ã…‡ã…‹ã„´"
    keyword_input = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥ (ì½¤ë§ˆ , ë¡œ êµ¬ë¶„)", value=default_keywords)
    
    st.markdown("---")
    st.caption("í•„í„°ë§í•  ì¹´í˜")
    all_options = ["ê³ ì–‘ì´ë¼ì„œ ë‹¤í–‰ì´ì•¼", "ëƒ¥ì´ë„¤", "ì•„ë°˜ê°•ê³ ", "ê°•ì‚¬ëª¨"]
    target_filter = st.multiselect("ì¹´í˜ ì„ íƒ", all_options, default=all_options)
    
    st.markdown("---")
    client_id = st.text_input("Client ID", type="password")
    client_secret = st.text_input("Secret", type="password")
    run_btn = st.button("ëª¨ë‹ˆí„°ë§ ì‹œì‘")

st.title(f"ğŸ•µï¸ '{keyword_input}' í†µí•© ë¶„ì„")

if run_btn:
    if not client_id or not client_secret:
        st.error("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        df, logs = get_naver_data_multi_keyword(keyword_input, client_id, client_secret)
        
        with st.expander("â„¹ï¸ ìˆ˜ì§‘ ë¡œê·¸"):
            if logs:
                for log in logs: st.write(log)
            else:
                st.write("ëª¨ë“  í‚¤ì›Œë“œ ì •ìƒ ìˆ˜ì§‘ë¨.")

        if df is not None and not df.empty:
            if target_filter:
                filtered_df = df[df['source'].isin(target_filter)]
            else:
                filtered_df = df
            
            # ìš”ì•½
            col1, col2, col3 = st.columns(3)
            # ìœ„í—˜ ê¸€ ê°œìˆ˜ (ì¼ë°˜ì´ ì•„ë‹Œ ê²ƒë“¤)
            risk_df = filtered_df[filtered_df['risk_level'] != "ì¼ë°˜"]
            risk_count = len(risk_df)
            top_src = filtered_df['source'].mode()[0] if not filtered_df.empty else "-"
                
            col1.metric("ì´ ìˆ˜ì§‘ ê¸€", f"{len(filtered_df)}ê±´")
            col2.metric("ğŸš¨ ì´ìŠˆ ê¸€", f"{risk_count}ê±´", delta_color="inverse")
            col3.metric("ìµœë‹¤ ì–¸ê¸‰", top_src)
            
            st.markdown("---")
            
            # 1. ì¼ë³„ ì¶”ì´ (ë‚ ì§œ ìˆëŠ” ê²ƒë§Œ)
            st.subheader("ğŸ“Š ì–¸ê¸‰ëŸ‰ ì¶”ì´")
            chart_df = filtered_df[filtered_df['postdate_dt'].dt.year > 2000]
            if not chart_df.empty:
                trend_data = chart_df['postdate_dt'].dt.date.value_counts().sort_index()
                st.area_chart(trend_data, color="#ff4b4b")
            
            st.markdown("---")

            # 2. íƒ­
            tab1, tab2, tab3 = st.tabs(["ğŸ”¥ ë¦¬ìŠ¤í¬ í”¼ë“œ", "ğŸ“Š í‚¤ì›Œë“œë³„ ì°¨íŠ¸", "ğŸ“ ì „ì²´ ë¦¬ìŠ¤íŠ¸"])
            
            with tab1:
                if risk_df.empty:
                    st.success("âœ… 'ë²Œë ˆ, ì´ë¬¼, êµ¬ë”ê¸°' ë“± ìœ„í—˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.caption("ğŸ‘‡ ì§€ì •í•˜ì‹  ìœ„í—˜ ë‹¨ì–´ê°€ í¬í•¨ëœ ê¸€ ëª©ë¡ì…ë‹ˆë‹¤.")
                    for i, row in risk_df.iterrows():
                        with st.container():
                            if row['postdate_dt'].year == 1900:
                                date_str = "âš¡ ìµœì‹  (ë‚ ì§œë¯¸ìƒ)"
                                date_color = "red"
                            else:
                                date_str = row['postdate_dt'].strftime('%Y-%m-%d')
                                date_color = "gray"
                            
                            st.markdown(f"**â˜• [{row['source']}]** <span style='color:{date_color}'>{date_str}</span>", unsafe_allow_html=True)
                            
                            # ì œëª©ê³¼ ìœ„í—˜ í‚¤ì›Œë“œ ê°•ì¡°
                            st.error(f"{row['clean_title']}")
                            st.write(f"âš ï¸ ê°ì§€ëœ ì´ìœ : **{row['risk_level']}** (ê²€ìƒ‰ì–´: {row['search_keyword']})")
                            st.caption(row['clean_desc'])
                            st.markdown(f"[ì›ë¬¸ ì´ë™]({row['link']})")
                            st.divider()
            
            with tab2:
                # ì–´ë–¤ ê²€ìƒ‰ì–´(ë¡œì–„ìºë‹Œ vs ë¡œìº)ë¡œ ë§ì´ ê±¸ë ¸ëŠ”ì§€ í™•ì¸
                if not filtered_df.empty:
                    st.write("ğŸ” ì–´ë–¤ ê²€ìƒ‰ì–´ë¡œ ê¸€ì´ ë§ì´ ì¡í˜”ì„ê¹Œìš”?")
                    st.bar_chart(filtered_df['search_keyword'].value_counts())

            with tab3:
                display = filtered_df.copy()
                display['ë‚ ì§œ'] = display['postdate_dt'].apply(lambda x: "âš¡ìµœì‹ " if x.year == 1900 else x.strftime('%Y-%m-%d'))
                
                st.dataframe(
                    display[['ë‚ ì§œ', 'source', 'clean_title', 'risk_level', 'search_keyword', 'link']],
                    column_config={"link": st.column_config.LinkColumn("ë§í¬")},
                    use_container_width=True
                )
            
            st.markdown("---")
            csv = filtered_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"{keyword_input}_monitoring.csv",
                mime="text/csv",
            )
        else:
            st.warning("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
